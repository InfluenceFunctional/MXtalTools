machine: "local"  # or "cluster"
device: "cuda"  # or "cpu"
anomaly_detection: False  # slows down the code
mode: null  # 'gan' or 'regression' or 'figures' or 'autoencoder' or 'embedding_regression' or 'sampling' WIP or 'embedding' 'mol_generation' WIP
#dataset_name: 'test_dataset.pkl' #
dataset_name: 'qm9_molecules_dataset.pkl' # 'test_dataset.pkl' #
#misc_dataset_name: 'misc_data_for_dataset.npy' #
misc_dataset_name: 'misc_data_for_qm9_molecules_dataset.npy' # 'misc_data_for_dataset.npy' #
#dataset_yaml_path: '/skinny_regression.yaml' #
dataset_yaml_path: null #'/dataset/qm9_autoencoder.yaml' # '/dataset/full_discriminator.yaml' #
base_config_path: null #'/experiments/base.yaml'  # base config
extra_test_set_name: null #'test_blind_test_dataset.pkl'  #'acridin_dataset.pkl' #'test_blind_test_dataset.pkl'
save_checkpoints: True # will do it always on cluster, only locally if True
checkpointing_loss_type: test  # will save a new checkpoint when a minimum of this is reached
model_names: null #['autoencoder'] #, 'embedding_regressor']
sweep_id: null #h38n3wfs
sweep_path: null #'C:/Users/mikem/OneDrive/NYU/CSD/MCryGAN/configs/autoencoder_tests/qm9_sweep3/qm9_sweep3.yaml'

dataset:
  max_dataset_length: 1000000
  test_fraction: 0.2
  filter_protons: False
  regression_target: null # crystal_reduced_volume #
  on_disk_data_dir: null
  dumps_rids: null
  single_identifier: null
  buffer_size: 100000
  resample_each: 10000000
  otf:
    smiles_source: null #'D:\crystal_datasets\zinc22'#'/home/mkilgour/crystal_datasets/zinc22/'  # /scratch/mk8347/zinc22
    build_size: 0 #100
    max_num_atoms: 30
    pare_to_size: 9
    max_num_heavy_atoms: 9
    space_group: 1
    max_radius: 15
    post_scramble_each: 10
    processes: 0 #4
    allowed_atom_types: [1, 6, 7, 8, 9]
  loader_processes: 0

# batching & convergence
num_samples: 1.0E+8
max_epoch_steps: 1.0E+8
early_epochs_step_override: 0
num_early_epochs: 0
grow_batch_size: False
min_batch_size: null
max_batch_size: null
batch_growth_increment: 1 # fraction of batch size to grow by each epoch
overfit_tolerance: null  # maximum allowed ratio of test_loss/train_loss
minimum_epochs: 0
max_epochs: null # 0 epochs takes us straight to sampling/evaluation (only implemented for GAN)
history: null  # for convergence checks
gradient_norm_clip: null
extra_test_period: null # # MUST BE MULTIPLE OF SAMPLE REPORTING FREQUENCY how often to evaluate on extra test sets (hardcoded analysis per extra test set)

logger:
  run_name: dev
  experiment_tag: dev
  mini_csp_frequency: 5  # how often to run CSP-style search WIP
  sample_reporting_frequency: 1  # how often to do detailed reporting with figures
  log_figures: True
  stats_reporting_frequency: 1
  dataset_reporting_time: 600 # seconds

sample_steps: 100

seeds:
  model: 12345
  dataset: 0

# for reloading prior checkpoints
model_paths:
  discriminator: null
  generator: null
  regressor: null
  autoencoder: null
  embedding_regressor: null
  polymorph_classifier: null
  crystal_regressor: null

positional_noise:
  discriminator: 0
  generator: 0
  regressor: 0
  autoencoder: 0
  crystal_regressor: 0

generate_sgs: null  #["P-1","P21/c","P212121","C2/c"] # null -> will generate in original sg.  'all' -> will randomly pick between all possibilities. []
supercell_size: 5

autoencoder:
  weight_constraint_factor: 0.9
  affine_scale_factor: null # 1
  infer_protons: False
  filter_protons: True
  nearest_node_loss_coefficient: 1
  clumping_loss_coefficient: 1
  nearest_component_loss_coefficient: 1
  type_distance_scaling: 2
  init_sigma: 1.05  # real-space valued
  evaluation_sigma: 0.35  # real-space valued
  sigma_lambda: 0.99
  sigma_threshold: 0.01
  overlap_eps:
    test: 1.0E-3
  max_overlap_threshold: 0.25
  node_weight_temperature: 1

  optimizer: null
  model: null

regressor:
  optimizer: null
  model: null

embedding_regressor:
  prediction_type: scalar
  num_targets: 1
  optimizer: null
  model: null

proxy_discriminator:
  train_on_randn: True
  embedding_type: 'autoencoder' # autoencoder, principal_axes, principal_moments, mol_volume
  train_encoder: False
  electrostatic_scaling_factor: 100  # training energy is scaled_lj + factor * es_energy
  train_on_mace: False
  train_on_bh: False  # alternatively, train on the Buckingham potential energy
  cutoff: 6

  model:
    hidden_dim: 1024
    dropout: 0
    norm: null
    num_layers: 4
    vector_norm: null

# for GAN training
generator:
  samples_per_iter: 5
  step_size: 1
  canonical_conformer_orientation: 'random' # 'standardized' 'random'

  #generator optimizer and model
  optimizer: null
  model:
    conditioner: null

discriminator:
  # settings
  train_on_randn: False
  train_on_distorted: False
  use_classification_loss: False
  use_rdf_distance_loss: False
  distortion_magnitude: -1 # -1 for wide range test # noise for distorted generation

  # discriminator optimizer and model
  optimizer: null
  model: null


polymorph_classifier:
  # polymorph_classifier optimizer and model
  optimizer: null
  model: null


  crystal_regressor:
    # crystal_regression optimizer and model
    optimizer: null
    model: null

