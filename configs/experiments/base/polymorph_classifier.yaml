machine: "local"  # or "cluster"
device: "cuda"  # or "cpu"
anomaly_detection: False  # slows down the code
mode: polymorph_classification
dataset_name: 'acridine_test_dataset.pkl'
misc_dataset_name: null #  fill for trajectory analysis
dataset_yaml_path: 'mol_classifier_dataset_dev.yaml' #
extra_test_set_name: null #
save_checkpoints: True # will do it always on cluster, only locally if True
checkpointing_loss_type: test  # will save a new checkpoint when a minimum of this is reached
model_names: ['polymorph_classifier']
sweep_id: null
sweep_path: null

dataset:
  type: 'mol_cluster'
  max_dataset_length: 10000000
  test_fraction: 0.2
  filter_protons: False
  regression_target: null

# batching & convergence
early_epochs_step_override: 5
num_early_epochs: 0
grow_batch_size: True
min_batch_size: 5
max_batch_size: 5
batch_growth_increment: 0 # fraction of batch size to grow by each epoch
overfit_tolerance: 4  # maximum allowed ratio of test_loss/train_loss
minimum_epochs: 50
max_epochs: 10000 # 0 epochs takes us straight to sampling/evaluation (only implemented for GAN)
history: 50  # for convergence checks
gradient_norm_clip: 1
extra_test_period: 4 # # MUST BE MULTIPLE OF SAMPLE REPORTING FREQUENCY how often to evaluate on extra test sets (hardcoded analysis per extra test set)

logger:
  run_name: dev
  experiment_tag: dev
  sample_reporting_frequency: 1  # how often to do detailed reporting with figures
  log_figures: True

seeds:
  model: 12345
  dataset: 0

# for reloading prior checkpoints
model_paths:
  polymorph_classifier: null

positional_noise:
  polymorph_classifier: 0

generate_sgs: null
supercell_size: 5

polymorph_classifier:
  # discriminator optimizer and model
  optimizer:
    optimizer: adamw
    init_lr: 1.0E-4
    max_lr: 1.0E-4
    min_lr: 1.0E-4
    lr_schedule: False
    beta1: 0.9
    beta2: 0.999
    weight_decay: 0.1
    convergence_eps: 0.0001
    lr_growth_lambda: 1.00
    lr_shrink_lambda: 0.95
    use_plateau_scheduler: False

  model:
    activation: 'gelu'

    graph:
      node_dim: 256
      message_dim: 128
      num_attention_heads: 16
      embedding_dim: 256
      num_convs: 4
      fcs_per_gc: 1
      num_radial: 32
      num_input_classes: 101
      norm: 'graph layer'
      dropout: 0.05

      atom_type_embedding_dim: 32
      radial_embedding: 'bessel'
      cutoff: 6
      max_num_neighbors: 100
      envelope_exponent: 5

    fc:
      hidden_dim: 256
      num_layers: 4
      dropout: 0.05
      norm: 'layer'