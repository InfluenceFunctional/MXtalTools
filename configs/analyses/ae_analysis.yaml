machine: "local"  # or "cluster"
device: "cuda"  # or "cpu"
anomaly_detection: False  # slows down the code
mode: autoencoder
dataset_name: 'eval_qm9_dataset.pt'
misc_dataset_name: 'misc_data_for_qm9_dataset.npy'
dataset_yaml_path: '/qm9_autoencoder.yaml' # '/dataset/full_discriminator.yaml' #
extra_test_set_name: null
save_checkpoints: True # will do it always on cluster, only locally if True
checkpointing_loss_type: test  # will save a new checkpoint when a minimum of this is reached
model_names: ['autoencoder']
sweep_id: null
sweep_path: null

dataset:
  type: 'molecule'
  max_dataset_length: 1000000
  test_fraction: 0.2
  regression_target: null

# batching & convergence
early_epochs_step_override: 5
num_early_epochs: 0
grow_batch_size: True
min_batch_size: 200
max_batch_size: 200
batch_growth_increment: 0.05 # fraction of batch size to grow by each epoch
overfit_tolerance: 4  # maximum allowed ratio of test_loss/train_loss
minimum_epochs: 2000
max_epochs: 10000 # 0 epochs takes us straight to sampling/evaluation (only implemented for GAN)
history: 100  # for convergence checks
gradient_norm_clip: 1
extra_test_period: 1 # unused

logger:
  run_name: ae_analysis
  experiment_tag: ae_analysis
  mini_csp_frequency: 1 # unused here
  sample_reporting_frequency: 1  # how often to do detailed reporting with figures
  log_figures: True

seeds:
  model: 12345
  dataset: 0

# for reloading prior checkpoints
model_paths:
  discriminator: null
  generator: null
  regressor: null
  autoencoder: null
  embedding_regressor: null

positional_noise:
  discriminator: 0
  generator: 0
  regressor: 0
  autoencoder: 0.01

generate_sgs: null
supercell_size: 5

autoencoder:
  infer_protons: False
  filter_protons: False
  nearest_node_loss_coefficient: 1
  clumping_loss_coefficient: 1
  type_distance_scaling: 2
  init_sigma: 1.05  # real-space valued
  evaluation_sigma: 0.35  # real-space valued
  sigma_lambda: 0.99
  sigma_threshold: 0.05
  overlap_eps:
    test: 1.0E-3
  max_overlap_threshold: 0.25
  node_weight_temperature: 1

  # discriminator optimizer and model
  optimizer:
    optimizer: adamw
    init_lr: 5.0E-5  # dummy
    encoder_init_lr: 1.0E-4
    decoder_init_lr: 1.0E-4
    max_lr: 1.0E-3
    min_lr: 1.0E-6
    lr_schedule: True
    beta1: 0.9
    beta2: 0.999
    weight_decay: 0.05
    convergence_eps: 1.0E-5
    lr_growth_lambda: 1.05
    lr_shrink_lambda: 0.99
    use_plateau_scheduler: False

  model:
    bottleneck_dim: 512
    encoder:
      activation: 'gelu'
      graph:
        node_dim: 512
        message_dim: 128
        embedding_dim: 512
        num_convs: 2
        fcs_per_gc: 2
        num_radial: 50
        norm: 'graph layer'
        dropout: 0
        vector_norm: 'graph vector layer'

        atom_type_embedding_dim: 32
        radial_embedding: 'bessel'
        cutoff: 3  # real space
        max_num_neighbors: 100
        envelope_exponent: 5

      fc: # generally unused
        hidden_dim: 256
        num_layers: 0
        dropout: 0
        norm: null
        vector_norm: 'vector layer'

    decoder:
      activation: 'gelu'
      fc:
        hidden_dim: 512
        num_layers: 4
        dropout: 0
        norm: 'layer'
        vector_norm: 'vector layer'

      num_nodes: 512
      ramp_depth: True


